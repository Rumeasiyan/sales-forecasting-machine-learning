{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Techniques for Sales Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost\n",
    "%pip install statsmodels\n",
    "%pip install pandas numpy statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "import hvplot.pandas\n",
    "from statsmodels.tsa.stattools import adfuller\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Datasets & Read all csv files\n",
    "\n",
    "files available at: https://www.kaggle.com/datasets/ndarshan2797/english-converted-datasets\n",
    "\n",
    "01. item_categories.csv - \n",
    "    item_category_name, \n",
    "    item_category_id\n",
    "\n",
    "02. items.csv - \n",
    "    item_name, \n",
    "    item_id, \n",
    "    category_id\n",
    "\n",
    "03. sales_train.csv - \n",
    "    date, \n",
    "    date_block_num, \n",
    "    shop_id, \n",
    "    item_id, \n",
    "    item_price, \n",
    "    item_cnt_day\n",
    "\n",
    "04. shops.csv - \n",
    "    shop_name, \n",
    "    shop_id\n",
    "\n",
    "05. test.csv - \n",
    "    ID, \n",
    "    shop_id, \n",
    "    item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "item_categories = pd.read_csv('./data-set/item_categories.csv')\n",
    "items = pd.read_csv('./data-set/items.csv')\n",
    "sales_train = pd.read_csv('./data-set/sales_train.csv')\n",
    "shops = pd.read_csv('./data-set/shops.csv')\n",
    "test = pd.read_csv('./data-set/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the shape of the data\n",
    "print(\"Shape of item_categories:\", item_categories.shape)\n",
    "print(\"Shape of items:\", items.shape)\n",
    "print(\"Shape of sales_train:\", sales_train.shape)\n",
    "print(\"Shape of shops:\", shops.shape)\n",
    "print(\"Shape of test:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the columns of the data\n",
    "print(\"\\n\\nColumns of item_categories:\\n\")\n",
    "print(item_categories.info())\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(\"\\n\\nColumns of items:\\n\")\n",
    "print(items.info())\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(\"\\n\\nColumns of sales_train:\\n\")\n",
    "print(sales_train.info())\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(\"\\n\\nColumns of shops:\\n\")\n",
    "print(shops.info())\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(\"\\n\\nColumns of test:\\n\")\n",
    "print(test.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the head and tail of the data\n",
    "\n",
    "print(\"\\n\\nHead of item_categories:\\n\")\n",
    "print(item_categories.head())\n",
    "\n",
    "print(\"\\n\\nTail of item_categories:\\n\")\n",
    "print(item_categories.tail())\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(\"\\n\\nHead of items:\\n\")\n",
    "print(items.head())\n",
    "\n",
    "print(\"\\n\\nTail of items:\\n\")\n",
    "print(items.tail())\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(\"\\n\\nHead of sales_train:\\n\")\n",
    "print(sales_train.head())\n",
    "\n",
    "print(\"\\n\\nTail of sales_train:\\n\")\n",
    "print(sales_train.tail())\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(\"\\n\\nHead of shops:\\n\")\n",
    "print(shops.head())\n",
    "\n",
    "print(\"\\n\\nTail of shops:\\n\")\n",
    "print(shops.tail())\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(\"\\n\\nHead of test:\\n\")\n",
    "print(test.head())\n",
    "\n",
    "print(\"\\n\\nTail of test:\\n\")\n",
    "print(test.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the data for better understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge sales_train.csv with items.csv on the \"item_id\" column\n",
    "sales_with_items = sales_train.merge(items, on='item_id', how='left')\n",
    "print(\"\\n\\nHead of sales_with_items:\\n\")\n",
    "print(sales_with_items.head(20))\n",
    "print(sales_with_items.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the result with item_categories.csv on the \"category_id\" \n",
    "sales_with_items_and_categories = sales_with_items.merge(item_categories, right_on='item_category_id', left_on='category_id', how='left')\n",
    "print(\"\\n\\nHead of sales_with_items_and_categories:\\n\")\n",
    "print(sales_with_items_and_categories.head(20))\n",
    "print(sales_with_items_and_categories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the two columns are the same\n",
    "if sales_with_items_and_categories['item_category_id'].equals(sales_with_items_and_categories['category_id']):\n",
    "    # If they are the same, drop one of the columns\n",
    "    sales_with_items_and_categories.drop(columns=['item_category_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nHead of sales_with_items_and_categories:\\n\")\n",
    "print(sales_with_items_and_categories.head(20))\n",
    "print(sales_with_items_and_categories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the result with shops.csv on the \"shop_id\" \n",
    "final_dataset = sales_with_items_and_categories.merge(shops, on='shop_id', how='left')\n",
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks the columns of the final dataset\n",
    "print(\"\\n\\nColumns of final_dataset:\\n\")\n",
    "print(final_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the date and date_block_num column to check whether they are related\n",
    "columns_to_print = ['date', 'date_block_num']\n",
    "print(final_dataset[columns_to_print])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column\n",
    "final_dataset.rename(columns={'date_block_num': 'month_num'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the column\n",
    "final_dataset.rename(columns={'item_cnt_day': 'item_cnt_month'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks the columns of the final dataset\n",
    "print(\"\\n\\nColumns of final_dataset:\\n\")\n",
    "print(final_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the final dataset to csv file\n",
    "final_dataset.to_csv('./data-set/output/final_dataset_without_cleaning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "\n",
    "#checking for missing values\n",
    "print(\"\\n\\nMissing values in final_dataset:\\n\")\n",
    "print(final_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "print(\"\\n\\nNull values in final_dataset:\\n\")\n",
    "print(final_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handles the missing values in final_dataset\n",
    "final_dataset['item_name'].fillna('Unknown', inplace=True)\n",
    "final_dataset['item_category_name'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes duplicates rows in final_dataset\n",
    "final_dataset.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks and solves the data type of the columns\n",
    "print(\"\\n\\nData types of final_dataset:\\n\")\n",
    "print(final_dataset.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #seems like item_cnt_month should be int64\n",
    "final_dataset['item_cnt_month'] = final_dataset['item_cnt_month'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints item_cnt_month column to check whether it is int64\n",
    "print(final_dataset['item_cnt_month'].head(30))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes -1 and 307980 from item_cnt_month column because it is an outlier\n",
    "#it is not possible to sell -1 and 307980 items in a day because 307980 is the total number of items sold in a day\n",
    "#which means that the data is incorrect\n",
    "#and -1 is not possible\n",
    "\n",
    "final_dataset = final_dataset[(final_dataset['item_cnt_month'] > 0) & (final_dataset['item_cnt_month'] < 307980)]\n",
    "\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier treatment\n",
    "\n",
    "#checks for outliers in the item_cnt_month column\n",
    "print(\"\\n\\nOutliers in item_cnt_month column:\\n\")\n",
    "print(final_dataset[final_dataset['item_cnt_month'] > 1000])\n",
    "\n",
    "#removes the outliers in the item_cnt_month column\n",
    "final_dataset = final_dataset[final_dataset['item_cnt_month'] < 1000]\n",
    "\n",
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with the incorrect data in the item_price column\n",
    "#the item_price should not be negative\n",
    "#the item_price should not be zero\n",
    "#the item_price should not be greater than 100000\n",
    "\n",
    "final_dataset = final_dataset[(final_dataset['item_price'] > 0) & (final_dataset['item_price'] < 100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handles special characters and formatting in the data set\n",
    "final_dataset['item_name'] = final_dataset['item_name'].str.replace('[^A-Za-z0-9А-Яа-я]+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes the noise in the item_name column\n",
    "final_dataset['item_name'] = final_dataset['item_name'].str.replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new column called revenue\n",
    "final_dataset['revenue'] = final_dataset['item_cnt_month'] * final_dataset['item_price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new column called revenue_per_item\n",
    "final_dataset['revenue_per_item'] = final_dataset['revenue'] / final_dataset['item_cnt_month']\n",
    "\n",
    "\n",
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks whether the revenue_per_item column and revenue column are the same\n",
    "\n",
    "if final_dataset['revenue_per_item'].equals(final_dataset['revenue']):\n",
    "    # If they are the same, drop one of the columns\n",
    "    final_dataset.drop(columns=['revenue_per_item'], inplace=True)\n",
    "\n",
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new column called date num\n",
    "final_dataset['date_num'] = final_dataset['date'].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new column called year num\n",
    "final_dataset['year_num'] = final_dataset['date'].str[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.shape)\n",
    "print(final_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange the columns\n",
    "final_dataset = final_dataset[['date', 'date_num', 'year_num', 'month_num', 'shop_id', 'shop_name', 'item_id', 'item_name', 'category_id', 'item_category_name', 'item_price', 'item_cnt_month', 'revenue']]\n",
    "\n",
    "print(final_dataset.shape)\n",
    "print(final_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data profiling\n",
    "\n",
    "#descriptive statistics\n",
    "print(\"\\n\\nDescriptive statistics of final_dataset:\\n\")\n",
    "print(final_dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data enrichment\n",
    "\n",
    "#creates a new column called month name\n",
    "final_dataset['month_name'] = final_dataset['month_num'].replace({0: 'January', 1: 'February', 2: 'March', 3: 'April', 4: 'May', 5: 'June', 6: 'July', 7: 'August', 8: 'September', 9: 'October', 10: 'November', 11: 'December', 12: 'January', 13: 'February', 14: 'March', 15: 'April', 16: 'May', 17: 'June', 18: 'July', 19: 'August', 20: 'September', 21: 'October', 22: 'November', 23: 'December', 24: 'January', 25: 'February', 26: 'March', 27: 'April', 28: 'May', 29: 'June', 30: 'July', 31: 'August', 32: 'September', 33: 'October'})\n",
    "\n",
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes month_num column\n",
    "\n",
    "final_dataset.drop(columns=['month_num'], inplace=True)\n",
    "\n",
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearange the columns\n",
    "\n",
    "final_dataset = final_dataset[['date', 'date_num', 'month_name', 'year_num', 'shop_id', 'shop_name', 'item_id', 'item_name', 'category_id', 'item_category_name', 'item_price', 'item_cnt_month', 'revenue']]\n",
    "\n",
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data binning\n",
    "\n",
    "#found the bins using the following code\n",
    "print(final_dataset['item_price'].max())\n",
    "print(final_dataset['item_price'].min())\n",
    "\n",
    "#creates a new column called price range\n",
    "final_dataset['price_range'] = pd.cut(final_dataset['item_price'], bins=[-1, 100, 200, 300, 400, 500, 600, 700, 800, 900, 100000], labels=['0-100', '100-200', '200-300', '300-400', '400-500', '500-600', '600-700', '700-800', '800-900', '900-100000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log transformation\n",
    "\n",
    "#creates a new column called log_revenue\n",
    "final_dataset['log_revenue'] = np.log(final_dataset['revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding\n",
    "\n",
    "#encodes the year_num column to 0, 1, 2\n",
    "\n",
    "final_dataset['year_num'] = final_dataset['year_num'].replace({'2013': 0, '2014': 1, '2015': 2})\n",
    "\n",
    "\n",
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping and aggregation\n",
    "\n",
    "#grouping the data set by shop_id and year_num and aggregating the item_cnt_month column using sum\n",
    "\n",
    "grouped_by_shop_id_and_year_num = final_dataset.groupby(['shop_id', 'year_num']).agg({'item_cnt_month': 'sum'})\n",
    "\n",
    "print(\"\\n\\nHead of grouped_by_shop_id_and_year_num:\\n\")\n",
    "print(grouped_by_shop_id_and_year_num.head(60))\n",
    "print(grouped_by_shop_id_and_year_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new column called scaled_revenue\n",
    "final_dataset['scaled_revenue'] = (final_dataset['revenue'] - final_dataset['revenue'].min()) / (final_dataset['revenue'].max() - final_dataset['revenue'].min())\n",
    "\n",
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change month_name column to numeric\n",
    "\n",
    "final_dataset['month_name'] = final_dataset['month_name'].replace({'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June':6, 'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November':11, 'December': 12})\n",
    "\n",
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#correlation\n",
    "\n",
    "numeric_columns = final_dataset.select_dtypes(include=['number'])\n",
    "print(\"\\n\\nCorrelation of final_dataset:\\n\")\n",
    "print(numeric_columns.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks for missing values\n",
    "print(\"\\n\\nMissing values in final_dataset:\\n\")\n",
    "print(final_dataset.isnull().sum())\n",
    "\n",
    "#checks for null values\n",
    "print(\"\\n\\nNull values in final_dataset:\\n\")\n",
    "print(final_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive analytics\n",
    "\n",
    "# Summary Statistics\n",
    "print(\"\\nDescriptive statistics of final_dataset:\")\n",
    "print(final_dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seasonality analysis\n",
    "\n",
    "grouped_by_month_name = final_dataset.groupby(['month_name']).agg({'item_cnt_month': 'sum'})\n",
    "\n",
    "print(\"\\n\\nHead of grouped_by_month_name:\\n\")\n",
    "print(grouped_by_month_name)\n",
    "print(grouped_by_month_name.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing seasonal decomposition\n",
    "decomposition = sm.tsa.seasonal_decompose(grouped_by_month_name, model='additive', period=1)\n",
    "\n",
    "#plotting the seasonal decomposition\n",
    "fig = decomposition.plot()\n",
    "plt.show()\n",
    "\n",
    "#plotting the item_cnt_month column\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(final_dataset['item_cnt_month'])\n",
    "plt.title('Item Count Per Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Item Count')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regulatory analytics\n",
    "\n",
    "grouped_by_shop_id_and_year_num = final_dataset.groupby(['shop_id', 'year_num']).agg({'item_cnt_month': 'sum'})\n",
    "\n",
    "print(\"\\n\\nHead of grouped_by_shop_id_and_year_num:\\n\")\n",
    "print(grouped_by_shop_id_and_year_num.head(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable Identification\n",
    "\n",
    "# Identify numerical and categorical variables\n",
    "numerical_vars = final_dataset.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_vars = final_dataset.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Print the list of numerical and categorical variables\n",
    "print(\"Numerical Variables:\")\n",
    "print(numerical_vars)\n",
    "\n",
    "print(\"\\nCategorical Variables:\")\n",
    "print(categorical_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate analysis\n",
    "\n",
    "for column in final_dataset.columns:\n",
    "    variable_type = final_dataset[column].dtype\n",
    "    \n",
    "    summary_stats = final_dataset[column].describe()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # For numerical variables, create a histogram\n",
    "    if variable_type in ['int64', 'float64']:\n",
    "        sns.histplot(data=final_dataset, x=column, kde=True)\n",
    "        plt.title(f'Distribution of {column}')\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel('Frequency')\n",
    "    \n",
    "    # For categorical variables, create a bar plot\n",
    "    else:\n",
    "        sns.countplot(data=final_dataset, x=column)\n",
    "        plt.title(f'Counts of {column}')\n",
    "        plt.xlabel(column)\n",
    "        plt.ylabel('Count')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"Summary Statistics for {column}:\")\n",
    "    print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bivariate analysis\n",
    "\n",
    "#can analysis by changing var1 and var2\n",
    "var1 = 'item_price'\n",
    "var2 = 'item_cnt_month'\n",
    "\n",
    "var1_type = final_dataset[var1].dtype\n",
    "var2_type = final_dataset[var2].dtype\n",
    "\n",
    "# Scatter Plot for Numerical vs. Numerical\n",
    "if var1_type in ['int64', 'float64'] and var2_type in ['int64', 'float64']:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=final_dataset, x=var1, y=var2)\n",
    "    plt.title(f'Scatter Plot: {var1} vs. {var2}')\n",
    "    plt.xlabel(var1)\n",
    "    plt.ylabel(var2)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Box Plot for Categorical vs. Numerical\n",
    "elif var1_type in ['object', 'category'] and var2_type in ['int64', 'float64']:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=final_dataset, x=var1, y=var2)\n",
    "    plt.title(f'Box Plot: {var1} vs. {var2}')\n",
    "    plt.xlabel(var1)\n",
    "    plt.ylabel(var2)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Bar Plot for Categorical vs. Categorical\n",
    "elif var1_type in ['object', 'category'] and var2_type in ['object', 'category']:\n",
    "    crosstab = pd.crosstab(final_dataset[var1], final_dataset[var2])\n",
    "    crosstab.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "    plt.title(f'Bar Plot: {var1} vs. {var2}')\n",
    "    plt.xlabel(var1)\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Print correlation for Numerical vs. Numerical\n",
    "if var1_type in ['int64', 'float64'] and var2_type in ['int64', 'float64']:\n",
    "    correlation = final_dataset[[var1, var2]].corr().iloc[0, 1]\n",
    "    print(f'Correlation between {var1} and {var2}: {correlation:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis (EDA)\n",
    "\n",
    "print(\"Dataset Overview:\")\n",
    "print(final_dataset.info())\n",
    "\n",
    "print(\"\\nSummary Statistics for Numerical Variables:\")\n",
    "print(final_dataset.describe())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(final_dataset.isnull().sum())\n",
    "\n",
    "numerical_columns = ['month_name', 'year_num', 'shop_id', 'item_id', 'category_id', 'item_price', 'item_cnt_month', 'revenue', 'log_revenue', 'scaled_revenue']\n",
    "\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(data=final_dataset, x=column, kde=True, bins=20)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize relationships between variables with a correlation matrix for numerical variables\n",
    "correlation_matrix = final_dataset[numerical_columns].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap for Numerical Variables\")\n",
    "plt.show()\n",
    "\n",
    "# Explore categorical variables with bar plots\n",
    "categorical_columns = ['shop_name', 'item_name', 'item_category_name', 'price_range']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=final_dataset, x=column)\n",
    "    plt.title(f'Counts of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inferential analysis\n",
    "\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=70, scale=10, size=100)\n",
    "\n",
    "# Create a DataFrame from the generated data\n",
    "df = pd.DataFrame({'measurement': data})\n",
    "\n",
    "# Calculate the sample mean and standard deviation\n",
    "sample_mean = df['measurement'].mean()\n",
    "sample_std = df['measurement'].std()\n",
    "\n",
    "# Define a hypothetical population mean for comparison\n",
    "population_mean = 75 \n",
    "\n",
    "# Perform a t-test to compare the sample mean with the population mean\n",
    "t_statistic, p_value = stats.ttest_1samp(df['measurement'], population_mean)\n",
    "\n",
    "# Print results\n",
    "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
    "print(f\"Sample Standard Deviation: {sample_std:.2f}\")\n",
    "print(f\"Population Mean: {population_mean}\")\n",
    "print(f\"T-Statistic: {t_statistic:.2f}\")\n",
    "print(f\"P-Value: {p_value:.4f}\")\n",
    "\n",
    "# Determine statistical significance\n",
    "alpha = 0.05  # Significance level (adjust as needed)\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The sample mean is statistically different from the population mean.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the sample mean and the population mean.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dianostic analytics\n",
    "\n",
    "# Generate a hypothetical dataset\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) * 10\n",
    "y = 3 * X + 2 + np.random.randn(100, 1)\n",
    "\n",
    "# Create a DataFrame from the generated data\n",
    "df = pd.DataFrame({'X': X.flatten(), 'y': y.flatten()})\n",
    "\n",
    "# Diagnostic Plots\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qualitative analytics\n",
    "\n",
    "category_counts = final_dataset['item_category_name'].value_counts()\n",
    "print(category_counts)\n",
    "\n",
    "cross_tab = pd.crosstab(final_dataset['shop_name'], final_dataset['item_category_name'])\n",
    "print(cross_tab)\n",
    "\n",
    "category_frequency = (final_dataset['price_range'] == 'Low').sum()\n",
    "print(f\"Frequency of 'Low' price range: {category_frequency}\")\n",
    "\n",
    "average_price_per_category = final_dataset.groupby('item_category_name')['item_price'].mean()\n",
    "print(average_price_per_category)\n",
    "\n",
    "category_counts.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Item Category Counts')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stationarity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column to datetime format\n",
    "final_dataset['date'] = pd.to_datetime(final_dataset['date'], format='%d.%m.%Y')\n",
    "\n",
    "monthly_data = final_dataset.groupby(final_dataset['date'].dt.to_period('M')).agg({\n",
    "    'item_cnt_month': 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "def adf_test(timeseries):\n",
    "    result = adfuller(timeseries, autolag='AIC')\n",
    "    print('ADF Statistic:', result[0])\n",
    "    print('p-value:', result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'   {key}: {value}')\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Stationary (Reject the null hypothesis)\")\n",
    "    else:\n",
    "        print(\"Non-Stationary (Fail to reject the null hypothesis)\")\n",
    "\n",
    "item_cnt_month_series = monthly_data['item_cnt_month']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(item_cnt_month_series)\n",
    "plt.title('Monthly Item Count Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Item Count')\n",
    "plt.show()\n",
    "\n",
    "adf_test(item_cnt_month_series)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nHead of final_dataset:\\n\")\n",
    "print(final_dataset.head(20))\n",
    "print(final_dataset.shape)\n",
    "print(final_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the final dataset to csv file\n",
    "final_dataset.to_csv('./data-set/output/final_dataset_with_cleaning.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development, Error Analysis & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the data for modeling\n",
    "df = pd.read_csv('./data-set/sales_train.csv')\n",
    "#rename item_cnt_day column\n",
    "df.rename(columns={'item_cnt_day': 'item_count'}, inplace=True)\n",
    "#removes duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "#outlier treatment\n",
    "df = df[(df['item_count'] > 0) & (df['item_count'] < 307980)]\n",
    "df = df[df['item_count'] < 1000]\n",
    "#handles incorrect data\n",
    "df = df[(df['item_price'] > 0) & (df['item_price'] < 100000)]\n",
    "#converts date column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y')\n",
    "#convert date to year-month format\n",
    "df['year-month'] = df['date'].dt.strftime('%Y-%m')\n",
    "#drop date column and item_price column\n",
    "df.drop(columns=['date', 'item_price'], inplace=True)\n",
    "# group features\n",
    "df_train_group = df.groupby(['year-month', 'shop_id', 'item_id']).sum().reset_index()\n",
    "# pivot table\n",
    "df = df_train_group.pivot_table(index=['shop_id', 'item_id'], columns='year-month', values='item_count', fill_value=0).reset_index()\n",
    "\n",
    "print(df.head(10))\n",
    "print(df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the final dataset to csv file\n",
    "final_dataset.to_csv('./data-set/output/dataset_for_modeling.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y variables for train and test sets\n",
    "X = df[df.columns[:-1]]\n",
    "y = df[df.columns[-1]]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating evaluation metrics\n",
    "scores_and_names = []\n",
    "\n",
    "# Create a function to evaluate the model\n",
    "def evaluate_the_model(y_true, y_pred, model_name, model):\n",
    "\n",
    "    # Calculate the MAE\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"MAE for {model_name}: {mae:.5f}\")\n",
    "\n",
    "    # Calculate the MSE\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    print(f\"MSE for {model_name}: {mse:.5f}\")\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"RMSE for {model_name}: {rmse:.5f}\")\n",
    "    \n",
    "    # Plot the predictions vs. the actual values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_true, label='Actual Values')\n",
    "    plt.plot(y_pred, label='Predicted Values')\n",
    "    plt.title(f'Predictions vs. Actual Values ({model_name})')\n",
    "    plt.xlabel('Observation')\n",
    "    plt.ylabel('Item Count')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    scores_and_names.append((model_name, rmse))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'Linear Regression', lin_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'Logistic Regression', log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a support vector machine model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'Support Vector Machine', svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a decision tree model\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'Decision Tree', dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random forest model\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'Random Forest', rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a stochastic gradient descent model\n",
    "sgd_reg = SGDRegressor()\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "y_pred = sgd_reg.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'Stochastic Gradient Descent', sgd_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xtra tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a extra trees model\n",
    "et = ExtraTreesRegressor()\n",
    "et.fit(X_train, y_train)\n",
    "y_pred = et.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'Extra Trees', et)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a xgboost model\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'XGBoost', xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ridge regression model\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'Ridge Regression', ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lasso regression model\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'Lasso Regression', lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ARIMA model\n",
    "arima = ARIMA(y_train, order=(1, 1, 1))\n",
    "model = arima.fit()\n",
    "y_pred = model.predict(start=len(y_train), end=len(y_train) + len(X_test) - 1, exog=X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'ARIMA', arima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create adaboost model\n",
    "ada = AdaBoostRegressor()\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'AdaBoost', ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bayesian ridge model\n",
    "br = BayesianRidge()\n",
    "br.fit(X_train, y_train)\n",
    "y_pred = br.predict(X_test)\n",
    "\n",
    "evaluate_the_model(y_test, y_pred, 'Bayesian Ridge', br)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a knn model\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(X_train.values, y_train.values)\n",
    "y_pred = knn.predict(X_test.values)\n",
    "\n",
    "evaluate_the_model(y_test.values, y_pred, 'K-Nearest Neighbors', knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(scores_and_names, columns=['Model', 'RMSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the results\n",
    "results.sort_values(by='RMSE', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the results in tabel format\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(final_dataset['date'], final_dataset['revenue'])\n",
    "plt.title('Revenue Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(final_dataset['shop_name'], final_dataset['revenue'])\n",
    "plt.title('Revenue by Shop')\n",
    "plt.xlabel('Shop Name')\n",
    "plt.ylabel('Revenue')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot\n",
    "sns.pairplot(final_dataset[['item_price', 'item_cnt_month', 'revenue']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=final_dataset, x='item_category_name', y='revenue')\n",
    "plt.title('Revenue by Item Category')\n",
    "plt.xlabel('Item Category')\n",
    "plt.ylabel('Revenue')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(data=final_dataset, x='item_price', y='revenue')\n",
    "plt.title('Revenue vs. Item Price')\n",
    "plt.xlabel('Item Price')\n",
    "plt.ylabel('Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=final_dataset, x='item_price', kde=True, bins=20)\n",
    "plt.title('Distribution of Item Count Per Month')\n",
    "plt.xlabel('Item Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#area plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.stackplot(final_dataset['date'], final_dataset['revenue'])\n",
    "plt.title('Revenue Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(numeric_columns.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "final_dataset['date'] = pd.to_datetime(final_dataset['date'])\n",
    "sns.lineplot(x='date', y='revenue', data=final_dataset)\n",
    "plt.title('Time Series Plot of Revenue')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_dataset.head(10))\n",
    "print(final_dataset.shape)\n",
    "print(final_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoding year_num column and month_name column\n",
    "final_dataset['year_num'] = final_dataset['year_num'].replace({0: '2013', 1: '2014', 2: '2015'})\n",
    "final_dataset['month_name'] = final_dataset['month_name'].replace({1: 'January', 2: 'February', 3: 'March', 4: 'April', 5: 'May', 6:'June', 7: 'July', 8: 'August', 9: 'September', 10: 'October', 11:'November', 12: 'December'})\n",
    "\n",
    "print(final_dataset.head(10))\n",
    "print(final_dataset.tail(10))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make data frame for the dashboard interactive\n",
    "df_interactive = final_dataset.interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates menu button for the dashboard to select years\n",
    "year_num_menu = pn.widgets.Select(name='Year', options=df_interactive['year_num'].unique().tolist(), value='2015')\n",
    "\n",
    "updated_year_df = df_interactive[df_interactive['year_num'] == year_num_menu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#montly revenue\n",
    "update_monthly_revenue = (updated_year_df.groupby('month_name')['revenue'].mean().to_frame().reset_index().sort_values(by='month_name').reset_index(drop=True))\n",
    "update_monthly_revenue_plot = update_monthly_revenue.hvplot.bar(x='month_name', y='revenue', rot=90, title='Average Revenue Per Month by year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly item count\n",
    "update_monthly_item_count = (updated_year_df.groupby('month_name')['item_cnt_month'].mean().to_frame().reset_index().sort_values(by='month_name').reset_index(drop=True))\n",
    "update_monthly_item_count_pie = update_monthly_item_count.plot(kind='pie', y='item_cnt_month', label='month_name', autopct='%1.1f%%', title='Average Item Count Per Month by year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales by category\n",
    "update_sales_by_category = (updated_year_df.groupby('item_category_name')['revenue'].mean().to_frame().reset_index().sort_values(by='revenue').reset_index(drop=True))\n",
    "update_sales_by_category_plot = update_sales_by_category.hvplot.area(x='item_category_name', y='revenue', rot=90, title='Average Revenue Per Category by year', height=500, width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales by shop\n",
    "update_sales_by_shop = (updated_year_df.groupby('shop_name')['revenue'].mean().to_frame().reset_index().sort_values(by='revenue').reset_index(drop=True))\n",
    "update_sales_by_shop_plot = update_sales_by_shop.hvplot.area(x='shop_name', y='revenue', rot=90, title='Average Revenue Per Shop by year', height=500, width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best selling category in all year\n",
    "update_best_selling_category = (df_interactive.groupby('item_category_name')['item_cnt_month'].mean().to_frame().reset_index().sort_values(by='item_cnt_month', ascending=False).reset_index(drop=True))\n",
    "update_best_selling_category_plot = update_best_selling_category.hvplot.barh(x='item_category_name', y='item_cnt_month', rot=90, title='Average Item Count Per Category', height=1000, width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates echarts bar for the dashboard to display revenue by year\n",
    "revenue_by_year_bar = { 'title' : { 'text' : 'Revenue by Year' }, 'tooltip' : { 'trigger': 'axis' }, 'legend': { 'data': ['Revenue'] }, 'xAxis' : { 'data' : final_dataset['year_num'].unique().tolist() }, 'yAxis' : { }, 'series' : [{ 'name' : 'Revenue', 'type' : 'bar', 'data' : final_dataset.groupby('year_num')['revenue'].sum().tolist() }] }\n",
    "revenue_by_year_echart_pane = pn.pane.ECharts(revenue_by_year_bar, width=400, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = pn.template.FastListTemplate(\n",
    "    title='Grocerry Sales Dashboard', \n",
    "    sidebar=[pn.pane.Markdown(\"# Revenue by Year\"),\n",
    "                revenue_by_year_echart_pane, \n",
    "             pn.pane.Markdown(\"#### Select Year\"), \n",
    "             year_num_menu],\n",
    "    main=[pn.Row(pn.Column(update_monthly_revenue_plot.panel(width=500)), \n",
    "                pn.Column(update_monthly_item_count_pie.panel(width=500), margin=(0,25)), \n",
    "                 ), \n",
    "          pn.Row(update_sales_by_category_plot),\n",
    "          pn.Row(update_sales_by_shop_plot),\n",
    "          pn.Row(update_best_selling_category_plot)],\n",
    "\n",
    "    accent_base_color=\"#88d8b0\",\n",
    "    header_background=\"#88d8b0\",\n",
    ")\n",
    "\n",
    "template.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
